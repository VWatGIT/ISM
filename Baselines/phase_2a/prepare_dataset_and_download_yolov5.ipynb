{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepate Data Folder Structure for YOLO format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected folder structure to train a Yolo Model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "YOLO_Project/\n",
    "│\n",
    "├── data/                     # Dataset and configuration files\n",
    "│   ├── images/               # All images (train/validation)\n",
    "│   │   ├── train/            # Training images\n",
    "│   │   │   ├── img1.jpg\n",
    "│   │   │   ├── img2.jpg\n",
    "│   │   │   └── ...\n",
    "│   │   └── val/              # Validation images\n",
    "│   │       ├── img1.jpg\n",
    "│   │       └── ...\n",
    "│   │\n",
    "│   └── labels/               # YOLO labels (bounding boxes)\n",
    "│       ├── train/            # Training labels (each .txt corresponds to an image)\n",
    "│       │   ├── img1.txt\n",
    "│       │   └── ...\n",
    "│       └── val/              # Validation labels\n",
    "│           ├── img1.txt\n",
    "│           └── ...\n",
    "│\n",
    "├── yolov5/                   # YOLOv5 repository (if using YOLOv5)\n",
    "│   └── ...                   # YOLOv5 scripts, config files, etc.\n",
    "│\n",
    "├── yolov8/                   # YOLOv8 repository (if using YOLOv8)\n",
    "│   └── ...                   # YOLOv8 scripts, config files, etc.\n",
    "│\n",
    "└── data.yaml                 # YOLO data configuration file (specifies paths, classes, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preparation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths to your data and annotations\n",
    "images_dir = \"/datax/Maack/ism_2024_2025/sample_solution/phase_2a/images\"\n",
    "annotations_path = \"/datax/Maack/ism_2024_2025/sample_solution/phase_2a/annotations_0_index.json\"\n",
    "output_dir = \"/datax/Maack/ism_2024_2025/sample_solution/phase_2a/yolo_training\"\n",
    "\n",
    "images_output_train = os.path.join(output_dir, \"images/train\")\n",
    "images_output_val = os.path.join(output_dir, \"images/val\")\n",
    "labels_output_train = os.path.join(output_dir, \"labels/train\")\n",
    "labels_output_val = os.path.join(output_dir, \"labels/val\")\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(images_output_train, exist_ok=True)\n",
    "os.makedirs(images_output_val, exist_ok=True)\n",
    "os.makedirs(labels_output_train, exist_ok=True)\n",
    "os.makedirs(labels_output_val, exist_ok=True)\n",
    "\n",
    "# Load COCO annotations\n",
    "with open(annotations_path) as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Function to convert COCO bbox to YOLO format\n",
    "def coco_to_yolo(bbox, img_width, img_height):\n",
    "    x_min, y_min, width, height = bbox\n",
    "    x_center = (x_min + width / 2) / img_width\n",
    "    y_center = (y_min + height / 2) / img_height\n",
    "    width /= img_width\n",
    "    height /= img_height\n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "# Split images into train and val\n",
    "image_files = [img['file_name'] for img in coco_data['images']]\n",
    "train_files, val_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create dictionaries to quickly access image information\n",
    "image_dict = {img['id']: img for img in coco_data['images']}\n",
    "annotations_dict = {}\n",
    "for annotation in coco_data['annotations']:\n",
    "    image_id = annotation['image_id']\n",
    "    if image_id not in annotations_dict:\n",
    "        annotations_dict[image_id] = []\n",
    "    annotations_dict[image_id].append(annotation)\n",
    "\n",
    "# Process images and annotations\n",
    "for img_file in coco_data['images']:\n",
    "    img_id = img_file['id']\n",
    "    img_name = img_file['file_name']\n",
    "    img_width = img_file['width']\n",
    "    img_height = img_file['height']\n",
    "\n",
    "    # Determine if the image is in train or val split\n",
    "    if img_name in train_files:\n",
    "        img_dest = os.path.join(images_output_train, os.path.basename(img_name))\n",
    "        label_dest = os.path.join(labels_output_train, os.path.basename(img_name).replace(\".jpg\", \".txt\"))\n",
    "    else:\n",
    "        img_dest = os.path.join(images_output_val, os.path.basename(img_name))\n",
    "        label_dest = os.path.join(labels_output_val, os.path.basename(img_name).replace(\".jpg\", \".txt\"))\n",
    "\n",
    "    # Copy the image to the corresponding directory\n",
    "    shutil.copy(os.path.join(images_dir, img_name), img_dest)\n",
    "\n",
    "    # Write YOLO annotation file\n",
    "    if img_id in annotations_dict:\n",
    "        with open(label_dest, 'w') as label_file:\n",
    "            for annotation in annotations_dict[img_id]:\n",
    "                category_id = annotation['category_id']\n",
    "                bbox = annotation['bbox']\n",
    "                x_center, y_center, width, height = coco_to_yolo(bbox, img_width, img_height)\n",
    "                label_file.write(f\"{category_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "print(\"Dataset preparation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the needed data.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Create the needed data.yaml file\n",
    "\n",
    "OUTPUT_YAML_DIR = \"/datax/Maack/ism_2024_2025/sample_solution/phase_2a/yolo_training\"\n",
    "\n",
    "data_yaml = {\n",
    "    \"train\": images_output_train,\n",
    "    \"val\": images_output_val,\n",
    "    \"nc\": len(coco_data['categories']),\n",
    "    \"names\": [cat['name'] for cat in coco_data['categories']]\n",
    "}\n",
    "\n",
    "# Save the data.yaml file\n",
    "with open(os.path.join(OUTPUT_YAML_DIR, \"data.yaml\"), 'w') as f:\n",
    "    yaml.dump(data_yaml, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone the Yolov5 Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone the repo into the /yolo_training folder via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd /datax/Maack/ism_2024_2025/sample_solution/phase_2a/yolo_training # Adapt to your directory structre\n",
    "git clone https://github.com/ultralytics/yolov5.git\n",
    "cd yolov5\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd into the yolov5 directory and run the following command to train the model on the custom dataset:\n",
    "\n",
    "# Adapt the /path/to/data.yaml to the path of your data.yaml file\n",
    "python train.py --img 640 --batch 16 --epochs 50 --data /path/to/data.yaml --cfg models/yolov5m.yaml --weights yolov5m.pt --name instrument_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare your Submission with script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Copy the yolov5 folder under yolo_training/yolov5 into the /submission/ folder\n",
    "2. Delete the __pycache__/ folder and/or other unnecessary folders to have <250 overall files in the yolov5 folder (>250 files per folder makes uploading to your huggingFace model repo for submission difficult)\n",
    "3. Now you can upload the content of submission/ folder to your HuggingFace Model Repo for submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
